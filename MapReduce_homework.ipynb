{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. \n",
    "\n",
    "#### MapReduce\n",
    "\n",
    "Use MapReduce to calculate the average housing price in each zip code and filter out records in which gross sqft is less than 500 and sale price is less than 100000. Round the average housing price to 2 decimals, and sort the output by housing price ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget -O housingSalseSample.csv https://github.com/CUSP2022ADS/Data/raw/main/housingSalseSample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "import functools\n",
    "from functools import reduce\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def returnInfo(record): #extract necessary fields from a data record (raw)\n",
    "    return(record['ZIP CODE'],record['GROSS SQUARE FEET'],record['SALE PRICE'])\n",
    "\n",
    "def filterData(record): #filter the records to keep only those listings over 500 sqfeet and 100000 dollars\n",
    "    # filter function must return True or False\n",
    "    if record[1]=='':\n",
    "        area = 0.0\n",
    "    if record[1]!='':\n",
    "        area = float(record[1])\n",
    "    if record[2]=='':\n",
    "        price = 0.0\n",
    "    if record[2]!='':\n",
    "        price = float(record[2])\n",
    "    if area > 500 and price > 100000:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def TotalPrice(result,record): #find the total price and number of properties by zipcode\n",
    "    zipcde,saleprice = record[0],float(record[2])\n",
    "\n",
    "    if zipcde not in result.keys():\n",
    "        result[zipcde] = [saleprice,1]\n",
    "    if zipcde in result.keys():\n",
    "        old_count = result[zipcde][1]\n",
    "        oldprice = result[zipcde][0]\n",
    "        new_count = old_count+1\n",
    "        new_price = ((oldprice+saleprice))\n",
    "        result.update({zipcde:[new_price,new_count]})\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "with open('housingSalseSample.csv', 'r') as fi:\n",
    "    reader = csv.DictReader(fi)\n",
    "    output = list(map(lambda x: (x[0],round((x[1][0]/x[1][1]), 2)), #find the average price dividing the price of all houses by number of houses\n",
    "                      reduce(TotalPrice,\n",
    "                             filter(filterData, \n",
    "                                    map(returnInfo,reader)),{}).items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sorted(output, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''grading function\n",
    "please pass your output into this function and upload the generated csv file \n",
    "together with your notebook to your GitHub repo'''\n",
    "\n",
    "def grading(output):\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(output,columns=['zipcode','price']).to_csv('output1.csv',index=False)\n",
    "\n",
    "grading(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. \n",
    "#### multiprocessing and Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O ADSSession2Task2Data.csv https://raw.githubusercontent.com/CUSP2022ADS/Data/main/ADSSession2Task2Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the chunk and MapReduce method to sum up each type's value in the synthetic datasetâ€”only keep records which $Select$ value is 1, and read 1000 lines in each chunk. Use multiprocessing package to deploy the task to multi-cores. The output should only have two columns: type and total value.\n",
    "\n",
    "Hint: filter function is not available in multiprocessing, implement an if-else function in the map or reduce step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                        ]      0 / 279369\r",
      "  2% [.                                                       ]   8192 / 279369\r",
      "  5% [...                                                     ]  16384 / 279369\r",
      "  8% [....                                                    ]  24576 / 279369\r",
      " 11% [......                                                  ]  32768 / 279369\r",
      " 14% [........                                                ]  40960 / 279369\r",
      " 17% [.........                                               ]  49152 / 279369\r",
      " 20% [...........                                             ]  57344 / 279369\r",
      " 23% [.............                                           ]  65536 / 279369\r",
      " 26% [..............                                          ]  73728 / 279369\r",
      " 29% [................                                        ]  81920 / 279369\r",
      " 32% [..................                                      ]  90112 / 279369\r",
      " 35% [...................                                     ]  98304 / 279369\r",
      " 38% [.....................                                   ] 106496 / 279369\r",
      " 41% [......................                                  ] 114688 / 279369\r",
      " 43% [........................                                ] 122880 / 279369\r",
      " 46% [..........................                              ] 131072 / 279369\r",
      " 49% [...........................                             ] 139264 / 279369\r",
      " 52% [.............................                           ] 147456 / 279369\r",
      " 55% [...............................                         ] 155648 / 279369\r",
      " 58% [................................                        ] 163840 / 279369\r",
      " 61% [..................................                      ] 172032 / 279369\r",
      " 64% [....................................                    ] 180224 / 279369\r",
      " 67% [.....................................                   ] 188416 / 279369\r",
      " 70% [.......................................                 ] 196608 / 279369\r",
      " 73% [.........................................               ] 204800 / 279369\r",
      " 76% [..........................................              ] 212992 / 279369\r",
      " 79% [............................................            ] 221184 / 279369\r",
      " 82% [.............................................           ] 229376 / 279369\r",
      " 85% [...............................................         ] 237568 / 279369\r",
      " 87% [.................................................       ] 245760 / 279369\r",
      " 90% [..................................................      ] 253952 / 279369\r",
      " 93% [....................................................    ] 262144 / 279369\r",
      " 96% [......................................................  ] 270336 / 279369\r",
      " 99% [....................................................... ] 278528 / 279369\r",
      "100% [........................................................] 279369 / 279369"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from functools import reduce\n",
    "import csv\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def returnInfo1(record): #extract necessary fields from a data record (raw)\n",
    "    return(record['Type'],record['Value'],record['Select'])\n",
    "\n",
    "def SumValues(result,record):\n",
    "    typez,vals,sel = record[0],record[1],record[2]\n",
    "    \n",
    "\n",
    "    if(sel=='1'):\n",
    "        \n",
    "        if typez not in result.keys():\n",
    "            result[typez] = float(vals)\n",
    "            \n",
    "        else:\n",
    "            old_val = result[typez]\n",
    "            new_val = 0\n",
    "            \n",
    "            if isinstance(old_val, list):\n",
    "              for i in old_val:\n",
    "                new_val = i+float(vals)\n",
    "            else:\n",
    "              new_val = old_val+float(vals)\n",
    "            result.update({typez:new_val})\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ADSSession2Task2Data.csv', 'r') as fi:\n",
    "    reader = csv.DictReader(fi)\n",
    "    chunk = []\n",
    "    result1 = []\n",
    "    chunksize = 1000\n",
    "    pool = Pool(8)\n",
    "    for i, line in enumerate(reader):\n",
    "        if (i % chunksize == 0 and i > 0):\n",
    "            output = list(reduce(SumValues,pool.map(returnInfo1,chunk),{}).items())\n",
    "            result1 += output\n",
    "            chunk = []\n",
    "        chunk.append(line)\n",
    "    output = list(reduce(SumValues,pool.map(returnInfo1,chunk),{}).items())\n",
    "    result1 += output\n",
    "    pool.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''grading function\n",
    "please pass your output into this function and upload the generated csv file \n",
    "together with your notebook to your GitHub repo'''\n",
    "\n",
    "def grading(output):\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(output,columns=['Type','Value']).to_csv('output2.csv',index=False)\n",
    "\n",
    "grading(result1) #Returns sum chunk by chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnInfo2(record): #extract necessary fields from a data record (raw)\n",
    "    return(record['Type'],record['Value'])\n",
    "\n",
    "def SumValues2(result,record):\n",
    "    typez,vals = record[0],record[1]\n",
    "    \n",
    "\n",
    "    if typez not in result.keys():\n",
    "        result[typez] = float(vals)\n",
    "        \n",
    "    else:\n",
    "        old_val = result[typez]\n",
    "        new_val = 0\n",
    "        \n",
    "        if isinstance(old_val, list):\n",
    "          for i in old_val:\n",
    "            new_val = i+float(vals)\n",
    "        else:\n",
    "          new_val = old_val+float(vals)\n",
    "          result.update({typez:new_val})\n",
    "          \n",
    "    return result\n",
    "\n",
    "with open('output2.csv', 'r') as fi:\n",
    "    reader = csv.DictReader(fi)\n",
    "    output3 = list(reduce(SumValues2,map(returnInfo2,reader),{}).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grading(output):\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(output,columns=['Type','Value']).to_csv('output3.csv',index=False)\n",
    "\n",
    "grading(output3) #Returns sum over the entire dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
